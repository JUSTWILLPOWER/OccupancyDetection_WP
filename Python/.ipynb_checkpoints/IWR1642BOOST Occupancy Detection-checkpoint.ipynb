{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#pyqtgraph -> fast plotting\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtGui\n",
    "%gui qt5\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the configuration file name\n",
    "\n",
    "configFileName = 'mmw_pplcount_demo_default.cfg'\n",
    "\n",
    "global CLIport\n",
    "global Dataport\n",
    "\n",
    "CLIport = {}\n",
    "Dataport = {}\n",
    "\n",
    "CLIport = serial.Serial('COM4', 115200)\n",
    "if not(CLIport.is_open):\n",
    "    CLIport.open()\n",
    "Dataport = serial.Serial('COM3', 921600)\n",
    "if not(Dataport.is_open):\n",
    "    Dataport.open()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfeDataOutputMode 1\n",
      "channelCfg 15 3 0\n",
      "adcCfg 2 1\n",
      "adcbufCfg 0 1 1 1 \n",
      "profileCfg 0 77 30 7 62 0 0 60 1 128 2500 0 0 30\n",
      "chirpCfg 0 0 0 0 0 0 0 1\n",
      "chirpCfg 1 1 0 0 0 0 0 2\n",
      "frameCfg 0 1 128 0 50 1 0\n",
      "lowPower 0 1\n",
      "guiMonitor 1 1 0 0\n",
      "cfarCfg 6 4 4 4 4 16 16 4 4 50 62 0\n",
      "doaCfg 600 1875 30 1\n",
      "SceneryParam -6 6 0.05 6\n",
      "GatingParam 4 3 2 0\n",
      "StateParam 10 5 10 100 5\n",
      "AllocationParam 450 0.01 25 1 2\n",
      "VariationParam 0.289 0.289 1.0\n",
      "PointCloudEn 1\n",
      "trackingCfg 1 2 250 20 200 50 90\n",
      "sensorStart\n"
     ]
    }
   ],
   "source": [
    "# Read the configuration file and send it to the board\n",
    "config = [line.rstrip('\\r\\n') for line in open(configFileName)]\n",
    "for i in config:\n",
    "    CLIport.write((i+'\\n').encode())\n",
    "    print(i)\n",
    "    time.sleep(0.01)\n",
    "\n",
    "#close control port\n",
    "CLIport.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise variables\n",
    "lostSync = False\n",
    "\n",
    "#valid header variables and constant\n",
    "magicBytes = np.array([2,1,4,3,6,5,8,7], dtype= 'uint8')\n",
    "\n",
    "isMagicOk = False\n",
    "isDataOk = False\n",
    "gotHeader = False\n",
    "\n",
    "frameHeaderLength = 52 #52 bytes long\n",
    "tlvHeaderLengthInBytes = 8\n",
    "pointLengthInBytes = 16\n",
    "frameNumber = 1\n",
    "targetFrameNumber = 0\n",
    "targetLengthInBytes = 68\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateChecksum(recieveHeader):\n",
    "    h = recieveHeader.view(dtype=np.uint16)\n",
    "    a = np.array([sum(h)], dtype=np.uint32)\n",
    "    b = np.array([sum(a.view(dtype=np.uint16))], dtype=np.uint16)\n",
    "    CS = np.uint16(~(b))\n",
    "    return CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readHeader(recieveHeader):\n",
    "    headerContent = dict()\n",
    "    index = 0\n",
    "    \n",
    "    headerContent['magicBytes'] = recieveHeader[index:index+8]\n",
    "    index += 20\n",
    "    \n",
    "    headerContent['packetLength'] = recieveHeader[index:index+4].view(dtype=np.uint32)\n",
    "    index += 4\n",
    "        \n",
    "    headerContent['frameNumber'] = recieveHeader[index:index+4].view(dtype=np.uint32)\n",
    "    index += 24\n",
    "    \n",
    "    headerContent['numTLVs'] = recieveHeader[index:index+2].view(dtype=np.uint16)\n",
    "    \n",
    "    return headerContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tlvParsing(data, dataLength, tlvHeaderLengthInBytes, pointLengthInBytes, targetLengthInBytes):\n",
    "    \n",
    "    targetDict = dict()\n",
    "    pointCloud = None\n",
    "    index = 0\n",
    "    #tlv header parsing\n",
    "    tlvType = data[index:index+4].view(dtype=np.uint32)\n",
    "    tlvLength = data[index+4:index+8].view(dtype=np.uint32)\n",
    "    #TLV size check\n",
    "    if (tlvLength + index > dataLength):\n",
    "        print('TLV SIZE IS WRONG')\n",
    "        lostSync = True\n",
    "        return\n",
    "    \n",
    "    index += tlvHeaderLengthInBytes\n",
    "    pointCloudDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "    if tlvType == 6: #point cloud TLV\n",
    "        numberOfPoints = pointCloudDataLength/pointLengthInBytes\n",
    "#         print('NUMBER OF POINTS ', str(int(numberOfPoints)))\n",
    "        if numberOfPoints > 0:\n",
    "            p = data[index:index+pointCloudDataLength[0]].view(dtype=np.single)\n",
    "            #form the appropriate array \n",
    "            #each point is 16 bytes - 4 bytes for each property - range, azimuth, doppler, snr\n",
    "            pointCloud = np.reshape(p,(4, int(numberOfPoints)),order=\"F\")\n",
    "    \n",
    "    #increment the index so it is possible to read the target list\n",
    "    index += pointCloudDataLength\n",
    "    #tlv header parsing\n",
    "    tlvType = data[index[0]:index[0]+4].view(dtype=np.uint32)\n",
    "    tlvLength = data[index[0]+4:index[0]+8].view(dtype=np.uint32)\n",
    "    index += tlvHeaderLengthInBytes\n",
    "    targetListDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "    if tlvType == 7: #target List TLV\n",
    "        \n",
    "        numberOfTargets = targetListDataLength/targetLengthInBytes\n",
    "        TID = np.zeros((1, int(numberOfTargets[0])), dtype = np.uint32) #tracking IDs\n",
    "        kinematicData = np.zeros((6, int(numberOfTargets[0])), dtype = np.single)\n",
    "        errorCovariance = np.zeros((9, int(numberOfTargets[0])), dtype = np.single)\n",
    "        gatingGain = np.zeros((1, int(numberOfTargets[0])), dtype = np.single)\n",
    "        \n",
    "        #increment the index so it is possible to read the target list\n",
    "        targetIndex = 0\n",
    "        while targetIndex != int(numberOfTargets):\n",
    "            TID[0][targetIndex] = data[index[0]:index[0]+4].view(dtype=np.uint32)\n",
    "            kinematicData[:,targetIndex] = data[index[0]+4:index[0]+28].view(dtype=np.single)\n",
    "            errorCovariance[:,targetIndex] = data[index[0]+28:index[0]+64].view(dtype=np.single)\n",
    "            gatingGain[:,targetIndex] = data[index[0]+64:index[0]+68].view(dtype=np.single)\n",
    "            index += targetLengthInBytes\n",
    "            targetIndex += 1\n",
    "            \n",
    "        targetDict['TID'] = TID\n",
    "        targetDict['kinematicData'] = kinematicData\n",
    "        targetDict['errorCovariance'] = errorCovariance\n",
    "        targetDict['gatingGain'] = gatingGain\n",
    "    \n",
    "    return pointCloud, targetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LiveClustering(pointsX, pointsY):\n",
    "    \n",
    "    #initialize constraints/variables\n",
    "    minClusterSize = 15\n",
    "    xMean = np.array([])\n",
    "    yMean = np.array([])\n",
    "    \n",
    "    if len(pointsX) >= minClusterSize:\n",
    "\n",
    "        clusterer = DBSCAN(eps=0.5, min_samples=20)\n",
    "        \n",
    "        clusterer.fit(pd.DataFrame(np.transpose(np.array([pointsX,pointsY]))).values)\n",
    "\n",
    "        if clusterer.core_sample_indices_.size > 0:\n",
    "            #array that contains the x,y positions and the cluster association number\n",
    "            clusters = np.array([pointsX[clusterer.core_sample_indices_],\n",
    "                      pointsY[clusterer.core_sample_indices_], \n",
    "                     clusterer.labels_[clusterer.core_sample_indices_]])\n",
    "            for centroidNumber in np.unique(clusters[2,:]):\n",
    "                xMean = np.append(xMean, np.mean(clusters[0,:][np.isin(clusters[2,:], centroidNumber)]))\n",
    "                yMean = np.append(yMean, np.mean(clusters[1,:][np.isin(clusters[2,:], centroidNumber)]))\n",
    "\n",
    "    return yMean, xMean\n",
    "\n",
    "def predict(x, P, A, Q): #predict function\n",
    "    xpred = np.matmul(A,x)\n",
    "    Ppred = np.matmul(A,P)\n",
    "    Ppred = np.matmul(Ppred,np.transpose(A)) + Q\n",
    "    return(xpred, Ppred)\n",
    "\n",
    "def innovation(xpred, Ppred, z, H, R): #innovation function\n",
    "    nu = z - np.matmul(H,xpred)\n",
    "    S = np.matmul(H,Ppred)\n",
    "    S = R + np.matmul(S, np.transpose(H))\n",
    "    return(nu, S)\n",
    "\n",
    "def innovation_update(xpred, Ppred, nu, S, H):\n",
    "    K = np.matmul(Ppred, np.transpose(H))\n",
    "    K = np.matmul(K,np.linalg.inv(S)) #check inverse function\n",
    "    xnew = xpred + np.matmul(K,nu)\n",
    "    Pnew = np.matmul(K,S)\n",
    "    Pnew = Ppred - np.matmul(Pnew,np.transpose(K)) \n",
    "    return(xnew, Pnew)\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def data_associate(centroidPred, rthetacentroid):\n",
    "    rthetacentroidCurrent = rthetacentroid\n",
    "    centpredCol = np.size(centroidPred,1)\n",
    "    rthetaCol = np.size(rthetacentroid,1)\n",
    "\n",
    "    for i in list(range(0,centpredCol)):\n",
    "        r1 = centroidPred[0][i]\n",
    "        r2 = rthetacentroid[0]\n",
    "        theta1 = centroidPred[2][i]\n",
    "        theta2 = rthetacentroid[1]\n",
    "        temp = np.sqrt(np.multiply(r1,r1) + np.multiply(r2,r2) - np.multiply(np.multiply(np.multiply(2,r1),r2),np.cos(theta2-theta1)))\n",
    "        if(i==0):\n",
    "            minDist = temp\n",
    "        else:\n",
    "            minDist = np.vstack((minDist,temp))\n",
    "\n",
    "    currentFrame = np.empty((2,max(centpredCol,rthetaCol)))\n",
    "    currentFrame[:] = np.nan\n",
    "\n",
    "    minDist = np.reshape(minDist, (centpredCol,rthetaCol))\n",
    "    minDistOrg = minDist\n",
    "\n",
    "    for i in list(range(0,min(centpredCol,rthetaCol))):\n",
    "        if((np.ndim(minDist)) == 1):\n",
    "            minDist = np.reshape(minDist,(rthetaCol,1))\n",
    "            minDistOrg = np.reshape(minDistOrg,(rthetaCol,1))\n",
    "        val = np.min(minDist)\n",
    "        resultOrg = np.argwhere(minDistOrg == val)\n",
    "        result = np.argwhere(minDist == val)\n",
    "        minRowOrg = resultOrg[0][0]\n",
    "        minColOrg = resultOrg[0][1]\n",
    "        minRow = result[0][0]\n",
    "        minCol = result[0][1]\n",
    "        currentFrame[:,minRowOrg] = rthetacentroid[:,minColOrg]\n",
    "        minDist = np.delete(minDist,minRow,0)\n",
    "        minDist = np.delete(minDist,minCol,1)\n",
    "        rthetacentroidCurrent = np.delete(rthetacentroidCurrent,minCol,1)\n",
    "\n",
    "    index = 0\n",
    "    if (rthetacentroidCurrent.size != 0): #check indexing\n",
    "        for i in list(range(centpredCol,rthetaCol)):\n",
    "            currentFrame[:,i] = rthetacentroidCurrent[:,index]\n",
    "            index += 1 \n",
    "\n",
    "    return(currentFrame)\n",
    "\n",
    "def LiveRKF(currentrawxycentroidData, centroidX, centroidP):\n",
    "    \n",
    "    #initialise matrices \n",
    "    delT = 0.0500\n",
    "    A = np.array([[1,delT,0,0], \n",
    "                  [0,1,0,0], \n",
    "                  [0,0,1,delT], \n",
    "                  [0,0,0,1]])\n",
    "    H = np.array([[1,0,0,0],\n",
    "                  [0,0,1,0]])\n",
    "    P = np.identity(4)\n",
    "    Q = np.multiply(0.9,np.identity(4))\n",
    "    R = np.array([[1],[1]])\n",
    "\n",
    "    xytransposecentroidData = currentrawxycentroidData\n",
    "    rthetacentroidData=xytransposecentroidData\n",
    "    if (xytransposecentroidData.size != 0): \n",
    "        [rthetacentroidData[0,:],rthetacentroidData[1,:]] = cart2pol(xytransposecentroidData[0,:],xytransposecentroidData[1,:])\n",
    "    if((rthetacentroidData.size != 0)):\n",
    "        currentFrame = data_associate(centroidX, rthetacentroidData)\n",
    "        addittionalCentroids = (np.size(rthetacentroidData,1)-np.size(centroidX,1))\n",
    "        if(addittionalCentroids>0):\n",
    "            centroidX = np.pad(centroidX, ((0,0),(0,addittionalCentroids)), 'constant') #initialises previous iteration to zer\n",
    "            for newFrameIndex in list((range(0, addittionalCentroids))):\n",
    "                centroidP.extend([P])\n",
    "        for currentFrameIndex in list((range(0,np.size(currentFrame,1)))):\n",
    "            if(not(np.isnan(currentFrame[0,currentFrameIndex]))):\n",
    "                [xpred, Ppred] = predict(centroidX[:,currentFrameIndex], centroidP[currentFrameIndex], A, Q)\n",
    "                [nu, S] = innovation(xpred, Ppred, currentFrame[:, currentFrameIndex], H, R)\n",
    "                [centroidX[:,currentFrameIndex],  centroidP[currentFrameIndex]] = innovation_update(xpred, Ppred, nu, S, H)\n",
    "            else:\n",
    "                [centroidX[:,currentFrameIndex], centroidP[currentFrameIndex]] = predict(centroidX[:,currentFrameIndex], centroidP[currentFrameIndex], A, Q)                   \n",
    "    else:\n",
    "        for noFrameIndex in list((range(0,np.size(centroidX,1)))):\n",
    "            [centroidX[:,noFrameIndex], centroidP[noFrameIndex]] = predict(centroidX[:,noFrameIndex], centroidP[noFrameIndex], A, Q)\n",
    "            \n",
    "    #centroidX is 4xN array that contains that centroid information for that frame\n",
    "    return centroidX, centroidP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read and parse data\n",
    "#plotting\n",
    "app = QtGui.QApplication([])\n",
    "\n",
    "# Set the plot \n",
    "pg.setConfigOption('background','w')\n",
    "win = pg.GraphicsWindow(title=\"Testing GUI\")\n",
    "p1 = win.addPlot()\n",
    "p2 = win.addPlot()\n",
    "p1.setXRange(-6,6)\n",
    "p1.setYRange(0,6)\n",
    "p1.setLabel('left',text = 'Y position (m)')\n",
    "p1.setLabel('bottom', text= 'X position (m)')\n",
    "p2.setXRange(-6,6)\n",
    "p2.setYRange(0,6)\n",
    "p2.setLabel('left',text = 'Y position (m)')\n",
    "p2.setLabel('bottom', text= 'X position (m)')\n",
    "s1 = p1.plot([],[],pen=None,symbol='o')\n",
    "s2 = p2.plot([],[],pen=None,symbol='x')\n",
    "\n",
    "#tracking variables\n",
    "centroidX =np.zeros((4,1))\n",
    "centroidP = []\n",
    "P = np.identity(4);\n",
    "centroidP.extend([P])\n",
    "\n",
    "while Dataport.is_open:\n",
    "#     print('In first while')\n",
    "    while (not(lostSync) and Dataport.is_open):\n",
    "        #check for a valid frame header\n",
    "        if not(gotHeader):\n",
    "#             print('In second while')\n",
    "            #in_waiting = amount of bytes in the buffer\n",
    "            rawRecieveHeader = Dataport.read(frameHeaderLength)\n",
    "#             print('after raw header recieved')\n",
    "            recieveHeader = np.frombuffer(rawRecieveHeader, dtype = 'uint8')\n",
    "#             print(recieveHeader)\n",
    "\n",
    "        #magic byte check\n",
    "        if not(np.array_equal(recieveHeader[0:8],magicBytes)):\n",
    "            print('MAGIC BYTES ARE WRONG')\n",
    "            lostSync = True\n",
    "            break\n",
    "\n",
    "        #valid the checksum\n",
    "        CS = validateChecksum(recieveHeader)\n",
    "        if (CS != 0):\n",
    "            print('HEADER CHECKSUM IS WRONG')\n",
    "            lostSync = True\n",
    "            break\n",
    "\n",
    "        #have a valid frame header\n",
    "        headerContent = readHeader(recieveHeader)\n",
    "\n",
    "        if (gotHeader):\n",
    "            if headerContent['frameNumber'] > targetFrameNumber:\n",
    "                targetFrameNumber = headerContent['frameNumber']\n",
    "                gotHeader = False\n",
    "                print('FOUND SYNC AT FRAME NUMBER ' + str(targetFrameNumber))\n",
    "            else:\n",
    "                print('OLD FRAME')\n",
    "                gotHeader = False\n",
    "                lostSync = True\n",
    "                break\n",
    "\n",
    "        dataLength = int(headerContent['packetLength'] - frameHeaderLength)\n",
    "     \n",
    "        if dataLength > 0:\n",
    "            #read the rest of the packet\n",
    "            rawData = Dataport.read(dataLength)\n",
    "            data = np.frombuffer(rawData, dtype = 'uint8')\n",
    "            \n",
    "            pointCloud, targetDict = tlvParsing(data, dataLength, tlvHeaderLengthInBytes, pointLengthInBytes,targetLengthInBytes)\n",
    "            \n",
    "            #target\n",
    "            if len(targetDict) != 0:\n",
    "                targetX = targetDict['kinematicData'][0,:]\n",
    "                targetY = targetDict['kinematicData'][1,:]\n",
    "                s2.setData(targetX,targetY)\n",
    "                QtGui.QApplication.processEvents() \n",
    "            \n",
    "            #pointCloud\n",
    "            if not(pointCloud is None):\n",
    "                #constrain point cloud to within the effective sensor range\n",
    "                #range 1 < x < 6\n",
    "                #azimuth -50 deg to 50 deg\n",
    "                #doppler is greater than 0 to remove static objects\n",
    "                #check whether corresponding range and azimuth data are within the constraints\n",
    "                \n",
    "                effectivePointCloud = np.array([])\n",
    "                for index in range(0, len(pointCloud[0,:])):\n",
    "                    if (pointCloud[0,index] > 1 and pointCloud[0,index] < 6) and (pointCloud[1, index] > -50*np.pi/180 and pointCloud[1, index] < 50*np.pi/180) and pointCloud[3,index] > 0:\n",
    "                        #concatenate columns to the new point cloud\n",
    "                        if len(effectivePointCloud) == 0:\n",
    "                            effectivePointCloud = np.reshape(pointCloud[:, index], (4,1), order=\"F\")\n",
    "                        else:\n",
    "                            point = np.reshape(pointCloud[:, index], (4,1),order=\"F\")\n",
    "                            effectivePointCloud = np.hstack((effectivePointCloud, point))\n",
    "\n",
    "                if len(effectivePointCloud) != 0:\n",
    "                    posX = np.multiply(effectivePointCloud[0,:], np.sin(effectivePointCloud[1,:]))\n",
    "                    posY = np.multiply(effectivePointCloud[0,:], np.cos(effectivePointCloud[1,:]))\n",
    "                    yMean, xMean = LiveClustering(posX, posY)\n",
    "                    centroidData = np.array([xMean, yMean])\n",
    "                    #track\n",
    "                    centroidX, centroidP = LiveRKF(centroidData, centroidX, centroidP)\n",
    "                    #plot\n",
    "                    #calculate x and y positions\n",
    "                    xPositions = np.multiply(centroidX[0,:], np.cos(centroidX[2,:]))\n",
    "                    yPositions = np.multiply(centroidX[0,:], np.sin(centroidX[2,:]))\n",
    "                    numberOfTargets = len(xPositions)\n",
    "                    s1.setData(xPositions, yPositions)\n",
    "#                     message = \"Occupancy Estimate: \" + str(numberOfTargets)\n",
    "#                     win.removeItem(occupancyEstimate)\n",
    "#                     occupancyEstimate = win.addLabel(text=message)\n",
    "                    QtGui.QApplication.processEvents() \n",
    "\n",
    "            \n",
    "    \n",
    "    while lostSync:\n",
    "        for rxIndex in range(0,8):\n",
    "            rxByte = Dataport.read(1)\n",
    "            rxByte = np.frombuffer(rxByte, dtype = 'uint8')\n",
    "            #if the byte received is not in sync with the magicBytes sequence then break and start again\n",
    "            if rxByte != magicBytes[rxIndex]:\n",
    "                break\n",
    "        \n",
    "        if rxIndex == 7: #got all the magicBytes\n",
    "            lostSync = False\n",
    "            #read the header frame\n",
    "            rawRecieveHeaderWithoutMagicBytes = Dataport.read(frameHeaderLength-len(magicBytes))\n",
    "            rawRecieveHeaderWithoutMagicBytes = np.frombuffer(rawRecieveHeaderWithoutMagicBytes, dtype = 'uint8')\n",
    "            #concatenate the magic bytes onto the header without magic bytes\n",
    "            recieveHeader = np.concatenate([magicBytes,rawRecieveHeaderWithoutMagicBytes], axis=0)\n",
    "            gotHeader = True\n",
    "            print('BACK IN SYNC')\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
