{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtCore, QtGui\n",
    "%gui qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up plottig GUI\n",
    "app = QtGui.QApplication([])\n",
    "pg.setConfigOption('background','w')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pg.GraphicsWindow(title=\"Occupancy Detection GUI\")\n",
    "plot1 = win.addPlot()\n",
    "plot1.setXRange(-6,6)\n",
    "plot1.setYRange(0,6)\n",
    "plot1.setLabel('left',text = 'Y position (m)')\n",
    "plot1.setLabel('bottom', text= 'X position (m)')\n",
    "s1 = plot1.plot([],[],pen=None,symbol='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readMeasurements(positionsDf):\n",
    "    #find headers and frames within headers\n",
    "    #each header has the structure frameNumber, X, Y\n",
    "    #below each header is the frame data\n",
    "    pointCloudPositions = list()\n",
    "    headerFound = False\n",
    "    for rowIndex in range(0, positionsDf.shape[0]):\n",
    "        row = positionsDf.loc[rowIndex]\n",
    "        if row[0] == 'FrameNumber' and row[1] == 'X' and row[2] == 'Y':\n",
    "            if headerFound: \n",
    "                #actual data was found last frame and this frame actual data is found again\n",
    "                #past frame ended so add to list\n",
    "                frame.index = pd.Series(np.arange(0, frame.shape[0])) #reindex the frame\n",
    "                pointCloudPositions.append(frame)\n",
    "                frame = pd.DataFrame([])\n",
    "            else:\n",
    "                #header found\n",
    "                headerFound = True\n",
    "                frame = pd.DataFrame([])\n",
    "            #data should be following\n",
    "        elif headerFound:\n",
    "            if np.isnan(np.float(row[1])) and np.isnan(np.float(row[2])):\n",
    "                #empty row \n",
    "                pointCloudPositions.append(frame)\n",
    "                headerFound = False\n",
    "                #only time its going to be NaN if the frame is completely empty\n",
    "            else:\n",
    "                #actual data\n",
    "                X = np.float(row[1])\n",
    "                Y = np.float(row[2])\n",
    "                frameNumber = int(row[0])\n",
    "                if len(frame) == 0:\n",
    "                    frame = pd.DataFrame({'X':X, 'Y':Y, 'FrameNumber':frameNumber}, index=range(1)) #first element of frame\n",
    "                else:\n",
    "                    data = pd.DataFrame({'X':X, 'Y':Y, 'FrameNumber':frameNumber}, index=range(frameNumber,frameNumber+1))\n",
    "                    frame = pd.concat([frame,data])\n",
    "\n",
    "    return pointCloudPositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterativeDfs(vertexID, edgeMatrix, startNode):\n",
    "    \n",
    "    visited = np.array([], dtype=np.int)\n",
    "    dfsStack = np.array([startNode])\n",
    "\n",
    "    while np.logical_not(np.equal(dfsStack.size,0)):\n",
    "        vertex, dfsStack = dfsStack[-1], dfsStack[:-1] #equivalent to stack pop function\n",
    "        if vertex not in visited:\n",
    "            #find unvisited nodes\n",
    "            unvisitedNodes = vertexID[np.logical_not(np.isnan(edgeMatrix[int(vertex), :]))]\n",
    "            visited = np.append(visited, vertex)\n",
    "            #add unvisited nodes to the stack\n",
    "            dfsStack = np.append(dfsStack, unvisitedNodes[np.logical_not(np.isin(unvisitedNodes,visited))])\n",
    "    \n",
    "    return visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph constraints and initialize variables\n",
    "weightThreshold = 0.2 #maximum distance between points\n",
    "minClusterSize = 30 #minimum cluster size\n",
    "centroidData = list()\n",
    "\n",
    "#read in data\n",
    "positionsDf = pd.read_csv('PointCloudData.csv', header=None)\n",
    "pointCloudPositions = readMeasurements(positionsDf)\n",
    "\n",
    "#to clear the information within the file\n",
    "#remove all information within the file\n",
    "# open('PointCloudData.csv', \"w\").close()\n",
    "\n",
    "for vertexDf in pointCloudPositions:\n",
    "    posX = vertexDf['X'].values\n",
    "    posY = vertexDf['Y'].values\n",
    "    #posX and posY given by \n",
    "    vertexID = np.arange(len(posX))\n",
    "    vertexList = np.arange(len(posX))\n",
    "    clusterDf = pd.DataFrame([], columns=['X', 'Y', 'CentroidNumber'])\n",
    "    clusterDf.to_csv('ClusterData.csv', mode='a', header=True, index=False)\n",
    "\n",
    "    if len(posX) >= minClusterSize:\n",
    "        edgeMatrix = np.zeros((len(posX), len(posY)))\n",
    "\n",
    "        #create distance matrix\n",
    "        #x1 - x0\n",
    "        xDifference = np.subtract(np.repeat(posX, repeats=len(posX)).reshape(len(posX), len(posX)), \n",
    "                                  np.transpose(np.repeat(posX, repeats=len(posX)).reshape(len(posX), len(posX))))\n",
    "        #y1 - y0\n",
    "        yDifference = np.subtract(np.repeat(posY, repeats=len(posY)).reshape(len(posY), len(posY)), \n",
    "                                  np.transpose(np.repeat(posY, repeats=len(posY)).reshape(len(posY), len(posY))))\n",
    "        #euclidean distance calculation\n",
    "        edgeMatrix = np.sqrt(np.add(np.square(xDifference), np.square(yDifference)))\n",
    "\n",
    "        #weight based reduction of graph/remove edges by replacing edge weight by np.NaN\n",
    "        weightMask = np.logical_or(np.greater(edgeMatrix,weightThreshold), np.equal(edgeMatrix, 0))\n",
    "        edgeMatrix[weightMask] = np.NaN\n",
    "\n",
    "        #perform iterative dfs\n",
    "        pointsX = np.array([])\n",
    "        pointsY = np.array([])\n",
    "\n",
    "        centroidNumber = 0\n",
    "        while vertexID.size > 0:\n",
    "            startNode = vertexID[0]\n",
    "            visited = iterativeDfs(vertexList, edgeMatrix, startNode)\n",
    "            #remove visited nodes (ie only slice off all unvisited nodes)\n",
    "            vertexID = vertexID[np.logical_not(np.isin(vertexID, visited))]\n",
    "            #visited is a component, extract cluster from it if possible\n",
    "            if visited.size >= minClusterSize:\n",
    "                pointsX = np.append(pointsX, posX[visited])\n",
    "                pointsY = np.append(pointsY, posY[visited]) \n",
    "\n",
    "        if pointsX.size == 0:\n",
    "            centroidDf = pd.DataFrame(np.expand_dims(np.array([np.NaN, np.NaN, 0]), axis=0))\n",
    "            centroidDf.to_csv('ClusterData.csv', mode='a', index=False, header=None)\n",
    "        else:\n",
    "            clusterer = DBSCAN(eps=0.5, min_samples=20)\n",
    "            clusterer.fit(pd.DataFrame(np.transpose(np.array([pointsX,pointsY]))).values)\n",
    "\n",
    "            if clusterer.core_sample_indices_.size > 0:\n",
    "                #array that contains the x,y positions and the cluster association number\n",
    "                clusters = np.array([pointsX[clusterer.core_sample_indices_],\n",
    "                          pointsY[clusterer.core_sample_indices_], \n",
    "                         clusterer.labels_[clusterer.core_sample_indices_]])\n",
    "                for centroidNumber in np.unique(clusters[2,:]):\n",
    "                    xMean = np.mean(clusters[0,:][np.isin(clusters[2,:], centroidNumber)])\n",
    "                    yMean = np.mean(clusters[1,:][np.isin(clusters[2,:], centroidNumber)])\n",
    "                    centroidDf = pd.DataFrame(np.expand_dims(np.array([xMean, yMean, centroidNumber]), axis=0))\n",
    "                    centroidDf.to_csv('ClusterData.csv', mode='a', index=False, header=None)\n",
    "            else:\n",
    "                centroidDf = pd.DataFrame(np.expand_dims(np.array([np.NaN, np.NaN, 0]), axis=0))\n",
    "                centroidDf.to_csv('ClusterData.csv', mode='a', index=False, header=None)\n",
    "    else:\n",
    "        centroidDf = pd.DataFrame(np.expand_dims(np.array([np.NaN, np.NaN, 0]), axis=0))\n",
    "        centroidDf.to_csv('ClusterData.csv', mode='a', index=False, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
