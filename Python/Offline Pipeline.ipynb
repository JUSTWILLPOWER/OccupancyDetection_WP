{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import cProfile\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from sklearn.cluster import KMeans\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtCore, QtGui\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from os import listdir\n",
    "import seaborn as sns \n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tlvParsing(data, tlvHeaderLengthInBytes, pointLengthInBytes, targetLengthInBytes):\n",
    "    \n",
    "    data = np.frombuffer(data, dtype = 'uint8')\n",
    "    \n",
    "    targetDict = dict()\n",
    "    pointCloud = np.array([])\n",
    "    index = 0\n",
    "    #tlv header parsing\n",
    "    tlvType = data[index:index+4].view(dtype=np.uint32)\n",
    "    tlvLength = data[index+4:index+8].view(dtype=np.uint32)\n",
    "    \n",
    "    index += tlvHeaderLengthInBytes\n",
    "    pointCloudDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "    if tlvType.size > 0 and tlvType == 6: #point cloud TLV\n",
    "        numberOfPoints = pointCloudDataLength/pointLengthInBytes\n",
    "        if numberOfPoints > 0:\n",
    "            p = data[index:index+pointCloudDataLength[0]].view(dtype=np.single)\n",
    "            #form the appropriate array \n",
    "            #each point is 16 bytes - 4 bytes for each property - range, azimuth, doppler, snr\n",
    "            pointCloud = np.reshape(p,(4, int(numberOfPoints)),order=\"F\")\n",
    "    \n",
    "    #increment the index so it is possible to read the target list\n",
    "    index += pointCloudDataLength\n",
    "    #tlv header parsing\n",
    "    tlvType = data[index[0]:index[0]+4].view(dtype=np.uint32)\n",
    "    tlvLength = data[index[0]+4:index[0]+8].view(dtype=np.uint32)\n",
    "    index += tlvHeaderLengthInBytes\n",
    "    targetListDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "    if tlvType.size > 0 and tlvType == 7: #target List TLV\n",
    "        \n",
    "        numberOfTargets = targetListDataLength/targetLengthInBytes\n",
    "        TID = np.zeros((1, int(numberOfTargets[0])), dtype = np.uint32) #tracking IDs\n",
    "        kinematicData = np.zeros((6, int(numberOfTargets[0])), dtype = np.single)\n",
    "        errorCovariance = np.zeros((9, int(numberOfTargets[0])), dtype = np.single)\n",
    "        gatingGain = np.zeros((1, int(numberOfTargets[0])), dtype = np.single)\n",
    "        \n",
    "        #increment the index so it is possible to read the target list\n",
    "        targetIndex = 0\n",
    "        while targetIndex != int(numberOfTargets[0]):\n",
    "            TID[0][targetIndex] = data[index[0]:index[0]+4].view(dtype=np.uint32)\n",
    "            kinematicData[:,targetIndex] = data[index[0]+4:index[0]+28].view(dtype=np.single)\n",
    "            errorCovariance[:,targetIndex] = data[index[0]+28:index[0]+64].view(dtype=np.single)\n",
    "            gatingGain[:,targetIndex] = data[index[0]+64:index[0]+68].view(dtype=np.single)\n",
    "            index += targetLengthInBytes\n",
    "            targetIndex += 1\n",
    "            \n",
    "        targetDict['TID'] = TID\n",
    "        targetDict['kinematicData'] = kinematicData\n",
    "        targetDict['errorCovariance'] = errorCovariance\n",
    "        targetDict['gatingGain'] = gatingGain\n",
    "    \n",
    "    return pointCloud, targetDict\n",
    "\n",
    "def parsePointCloud(pointCloud): #remove points that are not within the boundary\n",
    "    \n",
    "    effectivePointCloud = np.array([])\n",
    "    posX = np.array([])\n",
    "    posY = np.array([])\n",
    "    SNR = np.array([])\n",
    "    \n",
    "    for index in range(0, len(pointCloud[0,:])):\n",
    "        if (pointCloud[0,index] > 1 and pointCloud[0,index] < 6) \\\n",
    "        and (pointCloud[1, index] > -50*np.pi/180 \\\n",
    "            and pointCloud[1, index] < 50*np.pi/180):\n",
    "\n",
    "            #concatenate columns to the new point cloud\n",
    "            if len(effectivePointCloud) == 0:\n",
    "                effectivePointCloud = np.reshape(pointCloud[:, index], (4,1), order=\"F\")\n",
    "            else:\n",
    "                point = np.reshape(pointCloud[:, index], (4,1),order=\"F\")\n",
    "                effectivePointCloud = np.hstack((effectivePointCloud, point))\n",
    "\n",
    "    if len(effectivePointCloud) != 0:\n",
    "        posX = np.multiply(effectivePointCloud[0,:], np.sin(effectivePointCloud[1,:]))\n",
    "        posY = np.multiply(effectivePointCloud[0,:], np.cos(effectivePointCloud[1,:]))\n",
    "        SNR  = effectivePointCloud[3,:]\n",
    "    \n",
    "    return posX,posY,SNR\n",
    "\n",
    "def iterativeDfs(vertexID, edgeMatrix, startNode):\n",
    "    \n",
    "    visited = np.array([], dtype=np.int)\n",
    "    dfsStack = np.array([startNode])\n",
    "\n",
    "    while dfsStack.size > 0:\n",
    "        vertex, dfsStack = dfsStack[-1], dfsStack[:-1] #equivalent to stack pop function\n",
    "        if vertex not in visited:\n",
    "            #find unvisited nodes\n",
    "            unvisitedNodes = vertexID[np.logical_not(np.isnan(edgeMatrix[int(vertex), :]))]\n",
    "            visited = np.append(visited, vertex)\n",
    "            #add unvisited nodes to the stack\n",
    "            dfsStack = np.append(dfsStack, unvisitedNodes[np.logical_not(np.isin(unvisitedNodes,visited))])\n",
    "    \n",
    "    return visited\n",
    "\n",
    "def TreeClustering(posX, posY, SNR, weightThreshold, minClusterSize):\n",
    "    \n",
    "    vertexID = np.arange(len(posX))\n",
    "    vertexList = np.arange(len(posX))\n",
    "\n",
    "    associatedPoints = np.array([])\n",
    "\n",
    "    if len(posX) >= minClusterSize:\n",
    "        edgeMatrix = np.zeros((len(posX), len(posY)))\n",
    "\n",
    "        #create distance matrix\n",
    "        #x1 - x0\n",
    "        xDifference = np.subtract(np.repeat(posX, repeats=len(posX)).reshape(len(posX), len(posX)), \n",
    "                                  np.transpose(np.repeat(posX, repeats=len(posX)).reshape(len(posX), len(posX))))\n",
    "        #y1 - y0\n",
    "        yDifference = np.subtract(np.repeat(posY, repeats=len(posY)).reshape(len(posY), len(posY)), \n",
    "                                  np.transpose(np.repeat(posY, repeats=len(posY)).reshape(len(posY), len(posY))))\n",
    "        #euclidean distance calculation\n",
    "        edgeMatrix = np.sqrt(np.add(np.square(xDifference), np.square(yDifference)))\n",
    "\n",
    "        #weight based reduction of graph/remove edges by replacing edge weight by np.NaN\n",
    "        weightMask = np.logical_or(np.greater(edgeMatrix,weightThreshold), np.equal(edgeMatrix, 0))\n",
    "        edgeMatrix[weightMask] = np.NaN\n",
    "\n",
    "        #perform iterative dfs\n",
    "        associatedPoints = np.array([])\n",
    "        \n",
    "        centroidNumber = 0\n",
    "        while vertexID.size > 0:\n",
    "            startNode = vertexID[0]\n",
    "            visited = iterativeDfs(vertexList, edgeMatrix, startNode)\n",
    "            #remove visited nodes (ie only slice off all unvisited nodes)\n",
    "            vertexID = vertexID[np.logical_not(np.isin(vertexID, visited))]\n",
    "#             #visited is a component, extract cluster from it if possible\n",
    "            if visited.size >= minClusterSize:\n",
    "                cluster =  np.array([posX[visited], posY[visited],SNR[visited],\n",
    "                                     np.repeat(centroidNumber, repeats=len(visited))])\n",
    "                if associatedPoints.size == 0:\n",
    "                    associatedPoints = cluster\n",
    "                else:\n",
    "                    associatedPoints = np.hstack((associatedPoints, cluster))\n",
    "                centroidNumber += 1\n",
    "\n",
    "    return associatedPoints\n",
    "\n",
    "def predict(x, P, A, Q): #predict function\n",
    "    xpred = np.matmul(A,x)\n",
    "    Ppred = np.matmul(A,P)\n",
    "    Ppred = np.matmul(Ppred,np.transpose(A)) + Q\n",
    "    return(xpred, Ppred)\n",
    "\n",
    "def innovation(xpred, Ppred, z, H, R): #innovation function\n",
    "    nu = z - np.matmul(H,xpred)\n",
    "    S = np.matmul(H,Ppred)\n",
    "    S = R + np.matmul(S, np.transpose(H))\n",
    "    return(nu, S)\n",
    "\n",
    "def innovation_update(xpred, Ppred, nu, S, H):\n",
    "    K = np.matmul(Ppred, np.transpose(H))\n",
    "    K = np.matmul(K,np.linalg.inv(S)) #check inverse function\n",
    "    xnew = xpred + np.matmul(K,nu)\n",
    "    Pnew = np.matmul(K,S)\n",
    "    Pnew = Ppred - np.matmul(Pnew,np.transpose(K)) \n",
    "    return(xnew, Pnew)\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def data_associate(centroidPred, rthetacentroid):\n",
    "    minDist = np.array([])\n",
    "    rthetacentroidCurrent = rthetacentroid\n",
    "    centpredCol = np.size(centroidPred,1)\n",
    "    rthetaCol = np.size(rthetacentroid,1)\n",
    "\n",
    "    for i in list(range(0,centpredCol)):\n",
    "        r1 = centroidPred[0][i]\n",
    "        r2 = rthetacentroid[0]\n",
    "        theta1 = centroidPred[2][i]\n",
    "        theta2 = rthetacentroid[1]\n",
    "        temp = np.sqrt(np.multiply(r1,r1) + np.multiply(r2,r2) - np.multiply(np.multiply(np.multiply(2,r1),r2),np.cos(theta2-theta1)))\n",
    "        if(i==0):\n",
    "            minDist = temp\n",
    "        else:\n",
    "            minDist = np.vstack((minDist,temp))\n",
    "\n",
    "    currentFrame = np.empty((2,max(centpredCol,rthetaCol)))\n",
    "    currentFrame[:] = np.nan\n",
    "\n",
    "    minDist = np.reshape(minDist, (centpredCol,rthetaCol))\n",
    "    minDistOrg = minDist\n",
    "\n",
    "    for i in list(range(0,min(centpredCol,rthetaCol))):\n",
    "        if((np.ndim(minDist)) == 1):\n",
    "            minDist = np.reshape(minDist,(rthetaCol,1))\n",
    "            minDistOrg = np.reshape(minDistOrg,(rthetaCol,1))\n",
    "        val = np.min(minDist)\n",
    "        resultOrg = np.argwhere(minDistOrg == val)\n",
    "        result = np.argwhere(minDist == val)\n",
    "        minRowOrg = resultOrg[0][0]\n",
    "        minColOrg = resultOrg[0][1]\n",
    "        minRow = result[0][0]\n",
    "        minCol = result[0][1]\n",
    "        currentFrame[:,minRowOrg] = rthetacentroid[:,minColOrg]\n",
    "        minDist = np.delete(minDist,minRow,0)\n",
    "        minDist = np.delete(minDist,minCol,1)\n",
    "        rthetacentroidCurrent = np.delete(rthetacentroidCurrent,minCol,1)\n",
    "\n",
    "    index = 0\n",
    "    if (rthetacentroidCurrent.size != 0): #check indexing\n",
    "        for i in list(range(centpredCol,rthetaCol)):\n",
    "            currentFrame[:,i] = rthetacentroidCurrent[:,index]\n",
    "            index += 1 \n",
    "\n",
    "    return(currentFrame)\n",
    "\n",
    "def LiveRKF(currentrawxycentroidData, centroidX, centroidP, Q, R, isFirst):\n",
    "    \n",
    "    \n",
    "    #initialise matrices \n",
    "    delT = 0.0500\n",
    "    A = np.array([[1,delT,0,0], \n",
    "                  [0,1  ,0,0], \n",
    "                  [0,0,1,delT], \n",
    "                  [0,0,0,1]])\n",
    "    H = np.array([[1,0,0,0],\n",
    "                  [0,0,1,0]])\n",
    "    P = np.identity(4)\n",
    "\n",
    "    xytransposecentroidData = currentrawxycentroidData\n",
    "    rthetacentroidData=xytransposecentroidData\n",
    "    if (xytransposecentroidData.size != 0): \n",
    "        [rthetacentroidData[0,:],rthetacentroidData[1,:]] = cart2pol(xytransposecentroidData[0,:],xytransposecentroidData[1,:])\n",
    "    if(isFirst):\n",
    "        centroidX[[0,2],0] = rthetacentroidData[[0,1],0]\n",
    "        isFirst = 0\n",
    "    if((rthetacentroidData.size != 0)):\n",
    "        currentFrame = data_associate(centroidX, rthetacentroidData)\n",
    "        addittionalCentroids = (np.size(rthetacentroidData,1)-np.size(centroidX,1))\n",
    "        if(addittionalCentroids>0):\n",
    "            truncateCurrentFrame = currentFrame[:,np.size(centroidX,1):np.size(currentFrame,1)]\n",
    "            zeroTemplate = np.zeros((4,np.size(truncateCurrentFrame,1)),dtype=truncateCurrentFrame.dtype)\n",
    "            zeroTemplate[[0,2],:] = truncateCurrentFrame[[0,1],:]\n",
    "            centroidX = np.hstack((centroidX,zeroTemplate))\n",
    "            for newFrameIndex in list((range(0, addittionalCentroids))):\n",
    "                centroidP.extend([P])\n",
    "        for currentFrameIndex in list((range(0,np.size(currentFrame,1)))):\n",
    "            if(not(np.isnan(currentFrame[0,currentFrameIndex]))):\n",
    "                [xpred, Ppred] = predict(centroidX[:,currentFrameIndex], centroidP[currentFrameIndex], A, Q)\n",
    "                [nu, S] = innovation(xpred, Ppred, currentFrame[:, currentFrameIndex], H, R)\n",
    "                [centroidX[:,currentFrameIndex],  centroidP[currentFrameIndex]] = innovation_update(xpred, Ppred, nu, S, H)\n",
    "            else:\n",
    "                [centroidX[:,currentFrameIndex], centroidP[currentFrameIndex]] = predict(centroidX[:,currentFrameIndex], centroidP[currentFrameIndex], A, Q)                   \n",
    "    else:\n",
    "        for noFrameIndex in list((range(0,np.size(centroidX,1)))):\n",
    "            [centroidX[:,noFrameIndex], centroidP[noFrameIndex]] = predict(centroidX[:,noFrameIndex], centroidP[noFrameIndex], A, Q)\n",
    "    #centroidX is 4xN array that contains that centroid information for that frame\n",
    "    return centroidX, centroidP,isFirst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    tlvStream = tlvData[index]\n",
    "\n",
    "    #parsing\n",
    "    pointCloud, targetDict = tlvParsing(tlvStream, tlvHeaderLengthInBytes, pointLengthInBytes, targetLengthInBytes)\n",
    "\n",
    "    if pointCloud.size > 0:\n",
    "        posX,posY,SNR = parsePointCloud(pointCloud) #dictionary that contains the point cloud data\n",
    "\n",
    "        #initial noise reduction\n",
    "        clusters = TreeClustering(posX, posY, SNR,weightThresholdIntial, minClusterSizeInitial)\n",
    "\n",
    "        if clusters.size > 0:\n",
    "#             row 1 - x\n",
    "#             row 2 - y\n",
    "#             row 3 - SNR\n",
    "#             row 4 - cluster number\n",
    "#             snr zone snr test\n",
    "#             4.5 to the end -> last zone\n",
    "#             3-4.5m -> middle zone\n",
    "#             1-3m -> first zone\n",
    "            snrMask_LastZone = np.logical_and(np.greater(clusters[1,:], 4.5), np.greater(clusters[2,:], snrLastZone)) #zone 4.5m and greater\n",
    "            snrMask_MiddleZone = np.logical_and(np.logical_and(np.greater(clusters[1,:], 3), np.less_equal(clusters[1,:], 4.5)), \n",
    "                                                np.greater(clusters[2,:], snrMiddleZone)) #zone 3-4.5m with SNR > 20\n",
    "            snrMask_FirstZone = np.logical_and(np.less_equal(clusters[1,:], 3), np.greater(clusters[2,:], snrFirstZone))\n",
    "            overallSnrMask = np.logical_or(np.logical_or(snrMask_FirstZone,snrMask_MiddleZone), snrMask_LastZone)\n",
    "\n",
    "            snrFilteredClusters = clusters[:,overallSnrMask]\n",
    "\n",
    "            if snrFilteredClusters.size > 0:\n",
    "                dbClusters = TreeClustering(snrFilteredClusters[0,:], snrFilteredClusters[1,:], \n",
    "                                                snrFilteredClusters[2,:], \n",
    "                                                weightThresholdFinal, minClusterSizeFinal)\n",
    "                if dbClusters.size > 0:\n",
    "                    #row 1 - x\n",
    "                    #row 2 - y\n",
    "                    #row 3 - cluster number\n",
    "                    k = int(max(dbClusters[3,:])) + 1 \n",
    "                    points = np.transpose(np.array([dbClusters[0,:], dbClusters[1,:]]))\n",
    "\n",
    "                    #kmeans \n",
    "                    centroidClusterer = KMeans(n_clusters= k).fit(points)\n",
    "                    centroidData = np.array([centroidClusterer.cluster_centers_[:,0], centroidClusterer.cluster_centers_[:,1]])\n",
    "\n",
    "                    #tracking\n",
    "                    centroidX, centroidP,isFirst = LiveRKF(centroidData, centroidX, centroidP, Q, R, isFirst)\n",
    "                    #calculate x and y positions\n",
    "                    xPositions = np.multiply(centroidX[0,:], np.cos(centroidX[2,:]))\n",
    "                    yPositions = np.multiply(centroidX[0,:], np.sin(centroidX[2,:]))\n",
    "                    mask = np.logical_and((np.logical_and(xPositions<3,xPositions>-4)), np.logical_and(yPositions<5.5,yPositions>0.5))\n",
    "                    xPositions = xPositions[mask]\n",
    "                    yPositions= yPositions[mask]\n",
    "                    #keep centroids that are inside the constraints \n",
    "                    centroidX = centroidX[:,mask]\n",
    "\n",
    "                    #plot before/after snr reduction\n",
    "                    s1.setData(clusters[0,:], clusters[1,:])\n",
    "                    s2.setData(snrFilteredClusters[0,:], snrFilteredClusters[1,:])\n",
    "                    QtGui.QApplication.processEvents()\n",
    "    return centroidX, centroidP\n",
    "#                         key = input()\n",
    "#                         if key == 'q':\n",
    "#                             break\n",
    "\n",
    "\n",
    "#     if len(targetDict) != 0:\n",
    "#         #kinematic data object structure\n",
    "#         #row 0 - posX\n",
    "#         #row 1 - posY \n",
    "#         #row 2 - velX\n",
    "#         #row 3 - velY\n",
    "#         #row 4 - accX\n",
    "#         #row 5 - accY\n",
    "#         tiPosX = targetDict['kinematicData'][0,:]\n",
    "#         tiPosY = targetDict['kinematicData'][1,:]\n",
    "#         #enforce limits on TI \n",
    "#         mask = np.logical_and(np.logical_and(tiPosX<3,tiPosX>-4),np.logical_and(tiPosY<5.5,tiPosY>0.5))\n",
    "#         xTi = tiPosX[mask]\n",
    "#         yTi = tiPosY[mask]\n",
    "\n",
    "#     if groundTruthDataCollection:\n",
    "#         if clusters.size > 0:\n",
    "#             #enforce noise reduced point cloud v shape   \n",
    "#             xClusters = clusters[0,:]\n",
    "#             yClusters = clusters[1,:]\n",
    "#             mask = np.logical_and((np.logical_and(xClusters<3,xClusters>-4)), np.logical_and(yClusters<5.5,yClusters>0.5))\n",
    "#             xClusters = xClusters[mask]\n",
    "#             yClusters = yClusters[mask]\n",
    "#         #no one in ground truth\n",
    "#         if clusters.size > 0:\n",
    "#             s1.setData(xClusters, yClusters)\n",
    "#         else:\n",
    "#             print('AUTOFILL')\n",
    "#             s1.setData([],[])\n",
    "#             s2.setData([],[])\n",
    "#             QtGui.QApplication.processEvents()\n",
    "#             kalmanOutput = np.append(kalmanOutput, 111)\n",
    "#             clusteringOutput = np.append(clusteringOutput, 111)\n",
    "#             continue\n",
    "\n",
    "#         if snrFilteredClusters.size > 0:\n",
    "#             s2.setData(snrFilteredClusters[0,:],snrFilteredClusters[1,:])\n",
    "#         else:\n",
    "#             s2.setData([],[])\n",
    "\n",
    "#         QtGui.QApplication.processEvents()\n",
    "\n",
    "#         #labelling \n",
    "#         groundTruth = input('Ground Truth     : ')\n",
    "#         clustering = input('Number of Clusters: ')\n",
    "#         kalmanOutput = np.append(kalmanOutput, 1)\n",
    "#         clusteringOutput = np.append(clusteringOutput, 1)\n",
    "#     else:\n",
    "#         #if doing TI vs Alg\n",
    "\n",
    "#         #plotting code for TI vs Group16\n",
    "#         if len(targetDict) != 0:\n",
    "#             s1.setData(xTi, yTi)\n",
    "#             tiOutput = np.append(tiOutput, len(tiPosX))\n",
    "#             xLocationTI = np.append(xLocationTI,xTi)\n",
    "#             yLocationTI = np.append(yLocationTI, yTi)\n",
    "#         else:\n",
    "#             s1.setData([],[])\n",
    "#             tiOutput = np.append(tiOutput, len(tiPosX))\n",
    "#             xLocationTI = np.append(xLocationTI,np.NaN)\n",
    "#             yLocationTI = np.append(yLocationTI, np.NaN)\n",
    "\n",
    "#         if xPositions.size > 0:\n",
    "#             s2.setData(xPositions,yPositions)\n",
    "#             xGroup16 = np.append(xGroup16, xPositions)\n",
    "#             yGroup16 = np.append(yGroup16,yPositions)\n",
    "#             kalmanOutput = np.append(kalmanOutput, len(xPositions))\n",
    "#         else:\n",
    "#             s2.setData([],[])\n",
    "#             kalmanOutput = np.append(kalmanOutput, len(xPositions))\n",
    "#             xGroup16 = np.append(xGroup16, np.NaN)\n",
    "#             yGroup16 = np.append(yGroup16,np.NaN)\n",
    "\n",
    "#         QtGui.QApplication.processEvents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up plottig GUI\n",
    "app = QtGui.QApplication([])\n",
    "pg.setConfigOption('background','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "win.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pg.GraphicsWindow(title=\"Occupancy Detection GUI\")\n",
    "plot1 = win.addPlot()\n",
    "plot1.setXRange(-6,6)\n",
    "plot1.setYRange(0,6)\n",
    "plot1.setLabel('left',text = 'Y position (m)')\n",
    "plot1.setLabel('bottom', text= 'X position (m)')\n",
    "plot1.setLabel('top', text='Ground Truth')\n",
    "s1 = plot1.plot([],[],pen=None,symbol='o')\n",
    "s3 = plot1.plot([],[],pen=1)\n",
    "plot2 = win.addPlot()\n",
    "plot2.setXRange(-6,6)\n",
    "plot2.setYRange(0,6)\n",
    "plot2.setLabel('left',text = 'Y position (m)')\n",
    "plot2.setLabel('bottom', text= 'X position (m)')\n",
    "plot2.setLabel('top', text='Clustering')\n",
    "s2 = plot2.plot([],[],pen=None,symbol='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create constrained box \n",
    "xLimitMin = -4\n",
    "xLimitMax = 3\n",
    "yLimitMax = 6\n",
    "yLimitMin = 0.5\n",
    "\n",
    "horizontal = np.arange(start=xLimitMin, stop=xLimitMax,step=0.5)\n",
    "vertical = np.arange(start=yLimitMin, stop=yLimitMax, step=0.5)\n",
    "topSide = np.transpose(pd.DataFrame([horizontal,np.repeat(yLimitMax-0.5, repeats=len(horizontal))]).values)\n",
    "bottomSide = np.transpose(pd.DataFrame([horizontal,np.repeat(yLimitMin, repeats=len(horizontal))]).values)\n",
    "rightSide = np.transpose(pd.DataFrame([np.repeat(xLimitMax, repeats=len(vertical)), vertical]).values)\n",
    "leftSide = np.transpose(pd.DataFrame([np.repeat(xLimitMin-0.2, repeats=len(vertical)), vertical]).values)\n",
    "box = [topSide,bottomSide,rightSide,leftSide]\n",
    "for i in range(4):\n",
    "    plot1.plot(box[i], pen=(i,4))\n",
    "for i in range(4):\n",
    "    plot2.plot(box[i], pen=(i,4))\n",
    "QtGui.QApplication.processEvents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         190 function calls in 0.003 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.003    0.003 <ipython-input-15-e599dd38cda5>:1(pipeline)\n",
      "        1    0.002    0.002    0.002    0.002 <ipython-input-2-80acb5d44117>:1(tlvParsing)\n",
      "        1    0.001    0.001    0.001    0.001 <ipython-input-2-80acb5d44117>:54(parsePointCloud)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-2-80acb5d44117>:96(TreeClustering)\n",
      "        1    0.000    0.000    0.003    0.003 <string>:1(<module>)\n",
      "        9    0.000    0.000    0.000    0.000 fromnumeric.py:197(reshape)\n",
      "        9    0.000    0.000    0.000    0.000 fromnumeric.py:54(_wrapfunc)\n",
      "       14    0.000    0.000    0.000    0.000 numeric.py:541(asanyarray)\n",
      "        7    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
      "        7    0.000    0.000    0.000    0.000 shape_base.py:220(_warn_for_nonsequence)\n",
      "       14    0.000    0.000    0.000    0.000 shape_base.py:25(atleast_1d)\n",
      "        7    0.000    0.000    0.000    0.000 shape_base.py:286(hstack)\n",
      "        7    0.000    0.000    0.000    0.000 shape_base.py:335(<listcomp>)\n",
      "        1    0.000    0.000    0.003    0.003 {built-in method builtins.exec}\n",
      "        9    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "       27    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "        7    0.000    0.000    0.000    0.000 {built-in method numpy.concatenate}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.frombuffer}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       14    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "\n",
      "\n",
      "         10875 function calls in 0.112 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "      101    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1009(_handle_fromlist)\n",
      "      101    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:416(parent)\n",
      "        1    0.000    0.000    0.112    0.112 <ipython-input-15-e599dd38cda5>:1(pipeline)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-2-80acb5d44117>:1(tlvParsing)\n",
      "        1    0.000    0.000    0.000    0.000 <ipython-input-2-80acb5d44117>:54(parsePointCloud)\n",
      "        2    0.013    0.007    0.014    0.007 <ipython-input-2-80acb5d44117>:80(iterativeDfs)\n",
      "        2    0.002    0.001    0.016    0.008 <ipython-input-2-80acb5d44117>:96(TreeClustering)\n",
      "        1    0.000    0.000    0.112    0.112 <string>:1(<module>)\n",
      "       40    0.000    0.000    0.000    0.000 __init__.py:480(gen_batches)\n",
      "       20    0.000    0.000    0.000    0.000 __init__.py:669(get_chunk_n_rows)\n",
      "      121    0.000    0.000    0.000    0.000 _config.py:13(get_config)\n",
      "       20    0.000    0.000    0.000    0.000 _k_means.pyx:258(__pyx_fuse_1_centers_dense)\n",
      "       20    0.001    0.000    0.001    0.000 _k_means.pyx:258(_centers_dense)\n",
      "       50    0.000    0.000    0.000    0.000 _methods.py:34(_sum)\n",
      "        3    0.000    0.000    0.000    0.000 _methods.py:48(_count_reduce_items)\n",
      "        2    0.000    0.000    0.000    0.000 _methods.py:58(_mean)\n",
      "        1    0.000    0.000    0.000    0.000 _methods.py:91(_var)\n",
      "       21    0.000    0.000    0.000    0.000 _parallel_backends.py:254(__init__)\n",
      "       21    0.000    0.000    0.000    0.000 _parallel_backends.py:480(effective_n_jobs)\n",
      "      203    0.000    0.000    0.000    0.000 abc.py:137(__instancecheck__)\n",
      "      182    0.000    0.000    0.000    0.000 abc.py:141(__subclasscheck__)\n",
      "       21    0.000    0.000    0.001    0.000 arraysetops.py:484(in1d)\n",
      "       21    0.000    0.000    0.001    0.000 arraysetops.py:601(isin)\n",
      "      415    0.000    0.000    0.000    0.000 base.py:1190(isspmatrix)\n",
      "       51    0.000    0.000    0.001    0.000 einsumfunc.py:1002(einsum)\n",
      "       30    0.000    0.000    0.029    0.001 extmath.py:117(safe_sparse_dot)\n",
      "       20    0.000    0.000    0.000    0.000 extmath.py:25(squared_norm)\n",
      "       51    0.000    0.000    0.001    0.000 extmath.py:48(row_norms)\n",
      "      101    0.000    0.000    0.001    0.000 extmath.py:663(_safe_accumulator_op)\n",
      "       58    0.000    0.000    0.000    0.000 fromnumeric.py:1583(ravel)\n",
      "      101    0.000    0.000    0.001    0.000 fromnumeric.py:1966(sum)\n",
      "       12    0.000    0.000    0.000    0.000 fromnumeric.py:197(reshape)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:3014(mean)\n",
      "        1    0.000    0.000    0.000    0.000 fromnumeric.py:3250(var)\n",
      "        2    0.000    0.000    0.000    0.000 fromnumeric.py:41(_wrapit)\n",
      "       10    0.000    0.000    0.000    0.000 fromnumeric.py:429(repeat)\n",
      "       27    0.000    0.000    0.000    0.000 fromnumeric.py:54(_wrapfunc)\n",
      "        5    0.000    0.000    0.000    0.000 fromnumeric.py:592(transpose)\n",
      "      101    0.000    0.000    0.001    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "      101    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "       38    0.000    0.000    0.000    0.000 function_base.py:4641(append)\n",
      "       10    0.000    0.000    0.000    0.000 k_means_.py:147(_validate_center_shape)\n",
      "        1    0.000    0.000    0.000    0.000 k_means_.py:160(_tolerance)\n",
      "       30    0.000    0.000    0.000    0.000 k_means_.py:169(_check_sample_weight)\n",
      "        1    0.000    0.000    0.095    0.095 k_means_.py:184(k_means)\n",
      "       10    0.009    0.001    0.050    0.005 k_means_.py:43(_k_init)\n",
      "       10    0.031    0.003    0.091    0.009 k_means_.py:452(_kmeans_single_lloyd)\n",
      "       20    0.000    0.000    0.007    0.000 k_means_.py:581(_labels_inertia_precompute_dense)\n",
      "       20    0.000    0.000    0.007    0.000 k_means_.py:629(_labels_inertia)\n",
      "       10    0.000    0.000    0.051    0.005 k_means_.py:689(_init_centroids)\n",
      "        1    0.000    0.000    0.000    0.000 k_means_.py:913(__init__)\n",
      "        1    0.000    0.000    0.095    0.095 k_means_.py:941(fit)\n",
      "       10    0.000    0.000    0.000    0.000 numeric.py:175(ones)\n",
      "       20    0.000    0.000    0.000    0.000 numeric.py:293(full)\n",
      "      186    0.000    0.000    0.000    0.000 numeric.py:469(asarray)\n",
      "      231    0.000    0.000    0.000    0.000 numeric.py:541(asanyarray)\n",
      "      242    0.000    0.000    0.000    0.000 numerictypes.py:293(issubclass_)\n",
      "      121    0.000    0.000    0.000    0.000 numerictypes.py:365(issubdtype)\n",
      "       40    0.000    0.000    0.000    0.000 numpy_fix.py:10(<listcomp>)\n",
      "       40    0.000    0.000    0.000    0.000 numpy_fix.py:11(<listcomp>)\n",
      "       40    0.000    0.000    0.000    0.000 numpy_fix.py:8(concatenate)\n",
      "       20    0.000    0.000    0.003    0.000 pairwise.py:1197(_parallel_pairwise)\n",
      "       20    0.000    0.000    0.000    0.000 pairwise.py:1264(_check_chunk_size)\n",
      "       60    0.000    0.000    0.000    0.000 pairwise.py:1270(<genexpr>)\n",
      "       60    0.000    0.000    0.000    0.000 pairwise.py:1275(<genexpr>)\n",
      "       20    0.000    0.000    0.000    0.000 pairwise.py:1283(_precompute_metric_params)\n",
      "       40    0.000    0.000    0.004    0.000 pairwise.py:1301(pairwise_distances_chunked)\n",
      "       20    0.000    0.000    0.003    0.000 pairwise.py:1462(pairwise_distances)\n",
      "       30    0.001    0.000    0.033    0.001 pairwise.py:165(euclidean_distances)\n",
      "       20    0.000    0.000    0.000    0.000 pairwise.py:355(_argmin_min_reduce)\n",
      "       20    0.000    0.000    0.006    0.000 pairwise.py:361(pairwise_distances_argmin_min)\n",
      "       70    0.000    0.000    0.000    0.000 pairwise.py:37(_return_float_dtype)\n",
      "       50    0.000    0.000    0.005    0.000 pairwise.py:61(check_pairwise_arrays)\n",
      "       21    0.000    0.000    0.001    0.000 parallel.py:335(effective_n_jobs)\n",
      "       21    0.000    0.000    0.000    0.000 parallel.py:78(get_active_backend)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:209(_arrays_for_stack_dispatcher)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:220(_warn_for_nonsequence)\n",
      "       20    0.000    0.000    0.000    0.000 shape_base.py:25(atleast_1d)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:286(hstack)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:335(<listcomp>)\n",
      "       10    0.000    0.000    0.000    0.000 shape_base.py:83(atleast_2d)\n",
      "      182    0.000    0.000    0.001    0.000 validation.py:131(_num_samples)\n",
      "      101    0.000    0.000    0.000    0.000 validation.py:325(_ensure_no_complex_data)\n",
      "      101    0.001    0.000    0.007    0.000 validation.py:332(check_array)\n",
      "      101    0.001    0.000    0.003    0.000 validation.py:36(_assert_all_finite)\n",
      "       22    0.000    0.000    0.000    0.000 validation.py:763(check_random_state)\n",
      "      101    0.000    0.000    0.001    0.000 warnings.py:154(simplefilter)\n",
      "      101    0.000    0.000    0.000    0.000 warnings.py:170(_add_filter)\n",
      "      101    0.000    0.000    0.000    0.000 warnings.py:442(__init__)\n",
      "      101    0.001    0.000    0.001    0.000 warnings.py:463(__enter__)\n",
      "      101    0.000    0.000    0.000    0.000 warnings.py:482(__exit__)\n",
      "      203    0.000    0.000    0.000    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      182    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "      303    0.000    0.000    0.000    0.000 {built-in method _warnings._filters_mutated}\n",
      "       40    0.000    0.000    0.000    0.000 {built-in method builtins.any}\n",
      "        1    0.000    0.000    0.112    0.112 {built-in method builtins.exec}\n",
      "      273    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "     1104    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "     1418    0.000    0.000    0.001    0.000 {built-in method builtins.isinstance}\n",
      "      369    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "      395    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "       20    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "       24    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "      434    0.000    0.000    0.000    0.000 {built-in method numpy.array}\n",
      "       88    0.000    0.000    0.000    0.000 {built-in method numpy.concatenate}\n",
      "       30    0.000    0.000    0.000    0.000 {built-in method numpy.copyto}\n",
      "       51    0.001    0.000    0.001    0.000 {built-in method numpy.core._multiarray_umath.c_einsum}\n",
      "       50    0.029    0.001    0.029    0.001 {built-in method numpy.dot}\n",
      "       40    0.000    0.000    0.000    0.000 {built-in method numpy.empty}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.frombuffer}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.may_share_memory}\n",
      "       37    0.000    0.000    0.000    0.000 {built-in method numpy.zeros}\n",
      "       30    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'argmin' of 'numpy.ndarray' objects}\n",
      "       40    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "      121    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "       62    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      101    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "      101    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'mean' of 'numpy.ndarray' objects}\n",
      "       51    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "       10    0.011    0.001    0.011    0.001 {method 'randint' of 'mtrand.RandomState' objects}\n",
      "      100    0.000    0.000    0.000    0.000 {method 'ravel' of 'numpy.ndarray' objects}\n",
      "      155    0.001    0.000    0.001    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      101    0.000    0.000    0.000    0.000 {method 'remove' of 'list' objects}\n",
      "       10    0.000    0.000    0.000    0.000 {method 'repeat' of 'numpy.ndarray' objects}\n",
      "       41    0.000    0.000    0.000    0.000 {method 'reshape' of 'numpy.ndarray' objects}\n",
      "      101    0.000    0.000    0.000    0.000 {method 'rpartition' of 'str' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'sum' of 'numpy.ndarray' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'transpose' of 'numpy.ndarray' objects}\n",
      "       20    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "        9    0.000    0.000    0.000    0.000 {method 'view' of 'numpy.ndarray' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'centroidX' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-7445308239c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtlvData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mcProfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pipeline()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\cProfile.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(statement, filename, sort)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pyprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Utils\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrunctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\profile.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, statement, filename, sort)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mprof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m             \u001b[0mprof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\cProfile.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, cmd)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0m__main__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrunctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[1;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e599dd38cda5>\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                     \u001b[1;31m#tracking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                     \u001b[0mcentroidX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentroidP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0misFirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLiveRKF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroidData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentroidX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcentroidP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misFirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                     \u001b[1;31m#calculate x and y positions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mxPositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroidX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcentroidX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'centroidX' referenced before assignment"
     ]
    }
   ],
   "source": [
    "parsingMatFile = 'C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\Experiment 2\\\\2PeopleWalkingOppositeEndsLocation.mat'\n",
    "tlvData = (loadmat(parsingMatFile))['tlvStream'][0]\n",
    "\n",
    "#RKF \n",
    "centroidX =np.zeros((4,1))\n",
    "centroidP = []\n",
    "P = np.identity(4)\n",
    "centroidP.extend([P])\n",
    "Q = np.multiply(100,np.identity(4))\n",
    "R = np.multiply(0.01,np.array([[1],[1]]))\n",
    "#tree based\n",
    "weightThresholdIntial = 0.2 #minimum distance between points\n",
    "minClusterSizeInitial = 10\n",
    "weightThresholdFinal = 0.8 #minimum distance between points\n",
    "minClusterSizeFinal = 8 \n",
    "\n",
    "#zone snr\n",
    "snrFirstZone = 20\n",
    "snrMiddleZone = 15\n",
    "snrLastZone = 10\n",
    "\n",
    "tlvHeaderLengthInBytes = 8\n",
    "pointLengthInBytes = 16\n",
    "targetLengthInBytes = 68\n",
    "\n",
    "tiPosX = np.array([])\n",
    "tiPosY = np.array([])\n",
    "\n",
    "tiOutput = np.array([])\n",
    "kalmanOutput = np.array([])\n",
    "clusteringOutput = np.array([])\n",
    "snrFilteredClusters = np.array([])\n",
    "groundTruth = 0\n",
    "xPositions = np.array([])\n",
    "\n",
    "groundTruthDataCollection = False\n",
    "locationDataNeeded = False\n",
    "xGroup16 = np.array([])\n",
    "yGroup16 = np.array([])\n",
    "xLocationTI = np.array([])\n",
    "yLocationTI = np.array([])\n",
    "\n",
    "isFirst = 1\n",
    "\n",
    "for index in range(0, len(tlvData)):\n",
    "    cProfile.run('pipeline()')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write algVsTI to csv\n",
    "if locationDataNeeded:\n",
    "    labellingDf = pd.DataFrame(np.transpose(np.array([tiOutput, kalmanOutput,xLocationTI,yLocationTI,xGroup16,yGroup16])))\n",
    "    labellingDf.columns = ['TI', 'Group 16', 'xTi', 'yTi', 'xGroup16', 'yGroup16']\n",
    "    labellingDf.to_csv('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Results\\\\Algorithm vs TI\\\\LocationX3.csv')\n",
    "else:\n",
    "    labellingDf = pd.DataFrame(np.transpose(np.array([tiOutput, kalmanOutput])))\n",
    "    labellingDf.columns = ['TI', 'Group 16']\n",
    "    labellingDf.to_csv('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Results\\\\Algorithm vs TI\\\\XWalkingBetween.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
