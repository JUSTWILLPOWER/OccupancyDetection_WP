{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "#pyqtgraph -> fast plotting\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtGui\n",
    "%gui qt5\n",
    "import time\n",
    "from scipy.spatial.distance import euclidean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph(object):\n",
    "\n",
    "    def __init__(self, graphDict=None):\n",
    "        \"\"\" initializes a graph object \n",
    "            If no dictionary or None is given, \n",
    "            an empty dictionary will be used\n",
    "        \"\"\"\n",
    "        if graphDict == None:\n",
    "            graphDict = {}\n",
    "        self.graphDict = graphDict\n",
    "\n",
    "    def getVertices(self):\n",
    "        \"\"\" returns the vertices of a graph \"\"\"\n",
    "        return list(self.graphDict.keys())\n",
    "\n",
    "    def getEdges(self):\n",
    "        \"\"\" returns the edges of a graph \"\"\"\n",
    "        return self.generateEdges()\n",
    "\n",
    "    def addVertex(self, vertex):\n",
    "        \"\"\" If the vertex \"vertex\" is not in \n",
    "            self.graphDict, a key \"vertex\" with an empty\n",
    "            list as a value is added to the dictionary. \n",
    "            Otherwise nothing has to be done. \n",
    "        \"\"\"\n",
    "        if vertex not in self.graphDict:\n",
    "            self.graphDict[vertex] = []\n",
    "\n",
    "    def addEdge(self, edge):\n",
    "        \"\"\"  \n",
    "            between two vertices can be multiple edges! \n",
    "        \"\"\"\n",
    "        edge = set(edge)\n",
    "        (vertex1, vertex2) = tuple(edge)\n",
    "        if vertex1 in self.graphDict:\n",
    "            self.graphDict[vertex1].append(vertex2)\n",
    "        else:\n",
    "            self.graphDict[vertex1] = [vertex2]\n",
    "\n",
    "    def generateEdges(self):\n",
    "        \"\"\" A static method generating the edges of the \n",
    "            graph \"graph\". Edges are represented as sets \n",
    "            with one (a loop back to the vertex) or two \n",
    "            vertices \n",
    "        \"\"\"\n",
    "        edges = []\n",
    "        for vertex in self.graphDict:\n",
    "            for neighbour in self.graphDict[vertex]:\n",
    "                if {neighbour, vertex} not in edges:\n",
    "                    edges.append({vertex, neighbour})\n",
    "        return edges\n",
    "\n",
    "    def __str__(self):\n",
    "        res = \"vertices: \"\n",
    "        for k in self.graphDict:\n",
    "            res += str(k) + \" \"\n",
    "        res += \"\\nedges: \"\n",
    "        for edge in self.generateEdges():\n",
    "            res += str(edge) + \" \"\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stack:\n",
    "     def __init__(self):\n",
    "         self.items = []\n",
    "\n",
    "     def isEmpty(self):\n",
    "         return self.items == []\n",
    "\n",
    "     def push(self, item):\n",
    "         self.items.append(item)\n",
    "\n",
    "     def pop(self):\n",
    "         return self.items.pop()\n",
    "\n",
    "     def peek(self):\n",
    "         return self.items[len(self.items)-1]\n",
    "\n",
    "     def size(self):\n",
    "         return len(self.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one person slow walk\n",
    "#TLV Data Load\n",
    "tlvData = (loadmat('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\Matlab Data\\\\slowWalk.mat'))['tlvStream'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two people slow walk\n",
    "#TLV Data Load\n",
    "#loads of points\n",
    "tlvData = (loadmat('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\Matlab Data\\\\2PeopleMoving.mat'))['tlvStream'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#three people walk\n",
    "#TLV Data Load\n",
    "tlvData = (loadmat('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\Matlab Data\\\\3PeopleWalking.mat'))['tlvStream'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise variables\n",
    "lostSync = False\n",
    "\n",
    "#valid header variables and constant\n",
    "magicBytes = np.array([2,1,4,3,6,5,8,7], dtype= 'uint8')\n",
    "\n",
    "isMagicOk = False\n",
    "isDataOk = False\n",
    "gotHeader = False\n",
    "\n",
    "frameHeaderLength = 52 #52 bytes long\n",
    "tlvHeaderLengthInBytes = 8\n",
    "pointLengthInBytes = 16\n",
    "frameNumber = 1\n",
    "targetFrameNumber = 0\n",
    "targetLengthInBytes = 68\n",
    "\n",
    "#graph constraints\n",
    "weightThreshold = 0.2 #minimum distance between points\n",
    "minClusterSize = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QtGui.QApplication([])\n",
    "pg.setConfigOption('background','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pg.GraphicsWindow(title=\"Testing GUI\")\n",
    "plot1 = win.addPlot()\n",
    "plot1.setXRange(-6,6)\n",
    "plot1.setYRange(0,6)\n",
    "plot1.setLabel('left',text = 'Y position (m)')\n",
    "plot1.setLabel('bottom', text= 'X position (m)')\n",
    "s1 = plot1.plot([],[],pen=None,symbol='o')\n",
    "\n",
    "plot2 = win.addPlot()\n",
    "plot2.setXRange(-6,6)\n",
    "plot2.setYRange(0,6)\n",
    "plot2.setLabel('left',text = 'Y position (m)')\n",
    "plot2.setLabel('bottom', text= 'X position (m)')\n",
    "s2 = plot2.plot([],[],pen=None,symbol='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tlvStream in tlvData:\n",
    "    tlvStream = np.frombuffer(tlvStream, dtype = 'uint8')\n",
    "    \n",
    "    #tlv header\n",
    "    index = 0\n",
    "    #tlv header parsing\n",
    "    tlvType = tlvStream[index:index+4].view(dtype=np.uint32)\n",
    "    tlvLength = tlvStream[index+4:index+8].view(dtype=np.uint32)\n",
    "    \n",
    "    index += tlvHeaderLengthInBytes\n",
    "    tlvDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "\n",
    "    if tlvType == 6: \n",
    "        numberOfPoints = tlvDataLength/pointLengthInBytes\n",
    "        p = tlvStream[index:index+tlvDataLength[0]].view(np.single)\n",
    "        pointCloud = np.reshape(p,(4, int(numberOfPoints)),order=\"F\")\n",
    "\n",
    "        if not(pointCloud is None):\n",
    "            #constrain point cloud to within the effective sensor range\n",
    "            #range 1 < x < 6\n",
    "            #azimuth -50 deg to 50 deg\n",
    "            #check whether corresponding range and azimuth data are within the constraints\n",
    "\n",
    "            effectivePointCloud = np.array([])\n",
    "            for index in range(0, len(pointCloud[0,:])):\n",
    "                if (pointCloud[0,index] > 1 and pointCloud[0,index] < 6) \\\n",
    "                and (pointCloud[1, index] > -50*np.pi/180 \\\n",
    "                     and pointCloud[1, index] < 50*np.pi/180):\n",
    "        \n",
    "                    #concatenate columns to the new point cloud\n",
    "                    if len(effectivePointCloud) == 0:\n",
    "                        effectivePointCloud = np.reshape(pointCloud[:, index], (4,1), order=\"F\")\n",
    "                    else:\n",
    "                        point = np.reshape(pointCloud[:, index], (4,1),order=\"F\")\n",
    "                        effectivePointCloud = np.hstack((effectivePointCloud, point))\n",
    "                        \n",
    "\n",
    "            if len(effectivePointCloud) != 0:\n",
    "                posX = np.multiply(effectivePointCloud[0,:], np.sin(effectivePointCloud[1,:]))\n",
    "                posY = np.multiply(effectivePointCloud[0,:], np.cos(effectivePointCloud[1,:]))\n",
    "                #vertex dataframe\n",
    "                vertexID = np.arange(len(posX))\n",
    "                vertexDf = pd.DataFrame({'VertexID':vertexID, 'X':posX, 'Y':posY})\n",
    "                #minimum number of points to qualify as a person\n",
    "                if len(vertexDf.values) > 5:\n",
    "                    #preallocate edgeMatrix\n",
    "                    #edges are denoted by their respective weights\n",
    "                    #undirected graph with constraint that two nodes can only be connected by one edge\n",
    "                    edgeMatrix = np.zeros((len(posX), len(posY)))\n",
    "                    #vertices are saved as np arrays\n",
    "                    #evaluate edge Matrix and create graph\n",
    "                    for rowIndex in range(0, edgeMatrix.shape[0]):\n",
    "                        for colIndex in range(0, edgeMatrix.shape[1]):\n",
    "                            if rowIndex == colIndex:\n",
    "                                continue #diagonal element\n",
    "                            elif edgeMatrix[rowIndex, colIndex] != 0:\n",
    "                                continue #element already filled\n",
    "                            else:\n",
    "                                pointA = vertexDf.values[rowIndex][1:] #x,y point\n",
    "                                pointB = vertexDf.values[colIndex][1:] #x,y point\n",
    "                                length = euclidean(pointA, pointB)\n",
    "                                #fill elements\n",
    "                                edgeMatrix[rowIndex,colIndex] = length\n",
    "                                edgeMatrix[colIndex, rowIndex] = length\n",
    "                                \n",
    "                    #weight based reduction of graph/remove edges by replacing edge weight by np.NaN\n",
    "                    weightMask = np.logical_or(np.greater(edgeMatrix,weightThreshold), np.equal(edgeMatrix, 0))\n",
    "                    edgeMatrix[weightMask] = np.NaN\n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                    #perform DFS to find connected components\n",
    "                    componentsList = list()\n",
    "                    visitedSet = set()\n",
    "                    for vertex in vertexDf['VertexID']:\n",
    "                        if vertex == 0: #very first iteration\n",
    "                            visitedNodes = dfs(vertexDf, edgeMatrix, vertex)\n",
    "                            componentsList = visitedNodes\n",
    "                            visitedSet.add(visitedNodes)\n",
    "                        elif vertex not in visitedSet:\n",
    "                            visitedNodes = dfs(vertexDf, edgeMatrix, vertex)\n",
    "                            componentsList = visitedNodes\n",
    "                            visitedSet.add(visitedNodes)\n",
    "                else:\n",
    "                    print('NOT ENOUGH POINTS')\n",
    "\n",
    "            \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(vertexDf, edgeMatrix, startNode):\n",
    "    \n",
    "    #initialize\n",
    "    visited = set()\n",
    "    dfsStack = set()\n",
    "    \n",
    "    #dfs\n",
    "    while not(len(dfsStack) == 0):\n",
    "        vertex = dfsStack.pop()\n",
    "        if vertex not in visited:\n",
    "            visited.add(vertex)\n",
    "            #find next nodes to visit\n",
    "            #nodes must be connected to the current visited vertex and not in the visited list\n",
    "            #push those nodes to the stack\n",
    "            unvisitedNodes = edgeMatrix[vertex, not(np.isnan(edgeMatrix[vertex, :]))]\n",
    "            for node in unvisitedNodes:\n",
    "                dfsStack.add(node)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main code setup for unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs unit test and overall algorithm test set \n",
    "posX = np.array([2,2.1,2.2,2.1,2.2,2.2,5,5.1,5,4,5])\n",
    "posY = np.array([4,4,4,3.8,3.9,3.95,2,2,2.1,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unit test to check vertex and edge generation\n",
    "posX = np.array([1,1,1,2,3])\n",
    "posY = np.array([4,3,2,4,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'componentList' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-fa727cc2a25c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#use minimum cluster size to remove bad cluster matches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mclusterList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcomponentList\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mminClusterSize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mclusterList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusterList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'componentList' is not defined"
     ]
    }
   ],
   "source": [
    "#vertex dataframe\n",
    "vertexID = np.arange(len(posX))\n",
    "vertexDf = pd.DataFrame({'VertexID':vertexID, 'X':posX, 'Y':posY})\n",
    "#minimum number of points to qualify as a person\n",
    "if len(vertexDf.values) >= 5:\n",
    "    #preallocate edgeMatrix\n",
    "    #edges are denoted by their respective weights\n",
    "    #undirected graph with constraint that two nodes can only be connected by one edge\n",
    "    edgeMatrix = np.zeros((len(posX), len(posY)))\n",
    "    #vertices are saved as np arrays\n",
    "    #evaluate edge Matrix and create graph\n",
    "    for rowIndex in range(0, edgeMatrix.shape[0]):\n",
    "        for colIndex in range(0, edgeMatrix.shape[1]):\n",
    "            if rowIndex == colIndex:\n",
    "                continue #diagonal element\n",
    "            elif edgeMatrix[rowIndex, colIndex] != 0:\n",
    "                continue #element already filled\n",
    "            else:\n",
    "                pointA = (vertexDf.values[rowIndex])[1:] #extract x y position disregarding the vertexID\n",
    "                pointB = (vertexDf.values[colIndex])[1:] #extract x y position disregarding the vertexID\n",
    "                length = euclidean(pointA, pointB)\n",
    "                #fill elements\n",
    "                edgeMatrix[rowIndex,colIndex] = length\n",
    "                edgeMatrix[colIndex, rowIndex] = length\n",
    "\n",
    "    #weight based reduction of graph/remove edges by replacing edge weight by np.NaN\n",
    "    weightMask = np.logical_or(np.greater(edgeMatrix,weightThreshold), np.equal(edgeMatrix, 0))\n",
    "    edgeMatrix[weightMask] = np.NaN\n",
    "\n",
    "    #perform DFS to find connected components\n",
    "    componentsList = list() #list of components\n",
    "    vertexList = list() #used to hold vertices that have been considered\n",
    "    for vertex in vertexDf['VertexID']:\n",
    "        if vertex not in vertexList:\n",
    "            visitedNodes = dfs(vertexDf, edgeMatrix, vertex)\n",
    "            componentsList.append(visitedNodes)\n",
    "            for vertex in visitedNodes:\n",
    "                if vertex not in vertexList:\n",
    "                    vertexList.append(vertex)\n",
    "                    \n",
    "    #use minimum cluster size to remove bad cluster matches\n",
    "    clusterList = np.array([])\n",
    "    for cluster in componentsList:\n",
    "        if len(cluster) >= minClusterSize:\n",
    "            clusterList = np.append(clusterList, np.array(cluster))\n",
    "else:\n",
    "    print('NOT ENOUGH POINTS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(vertexDf, edgeMatrix, startNode):\n",
    "    \n",
    "    visited = []\n",
    "    dfsStack = [int(startNode)]\n",
    "\n",
    "    while not(len(dfsStack) == 0):\n",
    "        vertex = dfsStack.pop()\n",
    "        if vertex not in visited:\n",
    "            #find unvisited nodes\n",
    "            unvisitedNodes = vertexDf['VertexID'].values[np.logical_not(np.isnan(edgeMatrix[int(vertex), :]))]\n",
    "            unvisitedNodes = list(unvisitedNodes)\n",
    "            visited.append(vertex)\n",
    "            #add unvisited nodes to the stack\n",
    "            for node in unvisitedNodes:\n",
    "                if node not in visited:\n",
    "                    dfsStack.append(node)\n",
    "    return visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
