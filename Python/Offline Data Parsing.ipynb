{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#pyqtgraph -> fast plotting\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtGui\n",
    "%gui qt5\n",
    "\n",
    "import copy\n",
    "from scipy.io import loadmat\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from sklearn.cluster import DBSCAN\n",
    "import time\n",
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load relevant header data\n",
    "rawHeaderData = (loadmat('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\rawframeHeader.mat'))['rawframeHeader'][0]\n",
    "#preprocessing of header\n",
    "headerStream = np.array([])\n",
    "for number in rawHeaderData[0]:\n",
    "    headerStream = np.uint8(np.append(headerStream,number[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readHeader(recieveHeader):\n",
    "    headerContent = dict()\n",
    "    index = 0\n",
    "    \n",
    "    headerContent['magicBytes'] = recieveHeader[index:index+8]\n",
    "    index += 20\n",
    "    \n",
    "    headerContent['packetLength'] = recieveHeader[index:index+4].view(dtype=np.uint32)\n",
    "    index += 4\n",
    "        \n",
    "    headerContent['frameNumber'] = recieveHeader[index:index+4].view(dtype=np.uint32)\n",
    "    index += 24\n",
    "    \n",
    "    headerContent['numTLVs'] = recieveHeader[index:index+2].view(dtype=np.uint16)\n",
    "    \n",
    "    return headerContent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateChecksum(recieveHeader):\n",
    "    h = recieveHeader.view(dtype=np.uint16)\n",
    "    a = np.array([sum(h)], dtype=np.uint32)\n",
    "    b = np.array([sum(a.view(dtype=np.uint16))], dtype=np.uint16)\n",
    "    CS = np.uint16(~(b))\n",
    "    return CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise variables\n",
    "lostSync = False\n",
    "\n",
    "#valid header variables and constant\n",
    "magicBytes = np.array([2,1,4,3,6,5,8,7], dtype= 'uint8')\n",
    "\n",
    "isMagicOk = False\n",
    "isDataOk = False\n",
    "gotHeader = False\n",
    "\n",
    "frameHeaderLength = 52 #52 bytes long\n",
    "tlvHeaderLengthInBytes = 8\n",
    "pointLengthInBytes = 16\n",
    "frameNumber = 1\n",
    "targetFrameNumber = 0\n",
    "targetLengthInBytes = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = readHeader(headerStream)\n",
    "dataLength = int(header['packetLength'] - frameHeaderLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TLV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlvData = (loadmat('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\tlvData.mat'))['tlvData'][0][0]\n",
    "tlvStream = np.frombuffer(tlvData, dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Cloud Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tlv header\n",
    "index = 0\n",
    "#tlv header parsing\n",
    "tlvType = tlvStream[index:index+4].view(dtype=np.uint32)\n",
    "tlvLength = tlvStream[index+4:index+8].view(dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "index += tlvHeaderLengthInBytes\n",
    "tlvDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "\n",
    "if tlvType == 6: \n",
    "    numberOfPoints = tlvDataLength/pointLengthInBytes\n",
    "    p = tlvStream[index:index+tlvDataLength[0]].view(np.single)\n",
    "    pointCloud = np.reshape(p,(4, int(numberOfPoints)),order=\"F\")\n",
    "\n",
    "    pointCloudConstrained = np.array([])\n",
    "    if not(pointCloud is None):\n",
    "        #constrain point cloud to within the effective sensor range\n",
    "        #range 1 < x < 6\n",
    "        #azimuth -50 deg to 50 deg\n",
    "        #check whether corresponding range and azimuth data are within the constraints\n",
    "\n",
    "        effectivePointCloud = np.array([])\n",
    "        for index in range(0, len(pointCloud[0,:])):\n",
    "            if (pointCloud[0,index] > 1 and pointCloud[0,index] < 6) and (pointCloud[1, index] > -50*np.pi/180 and pointCloud[1, index] < 50*np.pi/180):\n",
    "                #concatenate columns to the new point cloud\n",
    "                if len(effectivePointCloud) == 0:\n",
    "                    effectivePointCloud = np.reshape(pointCloud[:, index], (4,1), order=\"F\")\n",
    "                else:\n",
    "                    point = np.reshape(pointCloud[:, index], (4,1),order=\"F\")\n",
    "                    effectivePointCloud = np.hstack((effectivePointCloud, point))\n",
    "\n",
    "        if len(effectivePointCloud) != 0:\n",
    "            posX = np.multiply(effectivePointCloud[0,:], np.sin(effectivePointCloud[1,:]))\n",
    "            posY = np.multiply(effectivePointCloud[0,:], np.cos(effectivePointCloud[1,:]))\n",
    "            \n",
    "            s.setData(posX,posY)\n",
    "            QtGui.QApplication.processEvents() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target List TLV Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index += tlvDataLength\n",
    "tlvType = tlvStream[index[0]:index[0]+4].view(dtype=np.uint32)\n",
    "tlvLength = tlvStream[index[0]+4:index[0]+8].view(dtype=np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n",
      "[144]\n",
      "[888]\n"
     ]
    }
   ],
   "source": [
    "print(tlvType)\n",
    "print(tlvLength)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "index += tlvHeaderLengthInBytes\n",
    "targetListDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "\n",
    "#setup target information objects\n",
    "numberOfTargets = targetListDataLength/targetLengthInBytes\n",
    "TID = np.zeros((1, int(numberOfTargets[0])), dtype = np.uint32) #tracking IDs\n",
    "kinematicData = np.zeros((6, int(numberOfTargets[0])), dtype = np.single)\n",
    "errorCovariance = np.zeros((9, int(numberOfTargets[0])), dtype = np.single)\n",
    "gatingGain = np.zeros((1, int(numberOfTargets[0])), dtype = np.single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetIndex = 0\n",
    "while targetIndex != int(numberOfTargets):\n",
    "    TID[0][targetIndex] = tlvStream[index[0]:index[0]+4].view(dtype=np.uint32)\n",
    "    kinematicData[:,targetIndex] = tlvStream[index[0]+4:index[0]+28].view(dtype=np.single)\n",
    "    errorCovariance[:,targetIndex] = tlvStream[index[0]+28:index[0]+64].view(dtype=np.single)\n",
    "    gatingGain[:,targetIndex] = tlvStream[index[0]+64:index[0]+68].view(dtype=np.single)\n",
    "    index += targetLengthInBytes\n",
    "    targetIndex += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TLV Data Load\n",
    "tlvData = (loadmat('C:\\\\Users\\\\hasna\\\\Documents\\\\GitHub\\\\OccupancyDetection\\\\Data\\\\ExperimentDraftData.mat'))['tlvStream'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise variables\n",
    "lostSync = False\n",
    "\n",
    "#valid header variables and constant\n",
    "magicBytes = np.array([2,1,4,3,6,5,8,7], dtype= 'uint8')\n",
    "\n",
    "isMagicOk = False\n",
    "isDataOk = False\n",
    "gotHeader = False\n",
    "\n",
    "frameHeaderLength = 52 #52 bytes long\n",
    "tlvHeaderLengthInBytes = 8\n",
    "pointLengthInBytes = 16\n",
    "frameNumber = 1\n",
    "targetFrameNumber = 0\n",
    "targetLengthInBytes = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = QtGui.QApplication([])\n",
    "pg.setConfigOption('background','w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "win1 = pg.GraphicsWindow(title=\"Point Cloud without DBSCAN\")\n",
    "p = win1.addPlot()\n",
    "p.setXRange(-6,6)\n",
    "p.setYRange(0,6)\n",
    "p.setLabel('left',text = 'Y position (m)')\n",
    "p.setLabel('bottom', text= 'X position (m)')\n",
    "s = p.plot([],[],pen=None,symbol='o')\n",
    "\n",
    "win2 = pg.GraphicsWindow(title=\"Point Cloud with DBSCAN\")\n",
    "p1 = win2.addPlot()\n",
    "p1.setXRange(-6,6)\n",
    "p1.setYRange(0,6)\n",
    "p1.setLabel('left',text = 'Y position (m)')\n",
    "p1.setLabel('bottom', text= 'X position (m)')\n",
    "s1 = p1.plot([],[],pen=None,symbol='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDBSCANDataset(posX, posY):\n",
    "    #create DBSCAN dataset - find a more efficient way to do this\n",
    "    dbscanDataSet = np.array([])\n",
    "    for pointIndex in range(0, len(posX)):\n",
    "        point = np.array([posX[pointIndex], posY[pointIndex]])\n",
    "        if pointIndex == 0:\n",
    "            dbscanDataSet = [point]\n",
    "        else:\n",
    "            dbscanDataSet = np.append(dbscanDataSet, [point], axis=0)\n",
    "    return dbscanDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db is the output of the dbscan algorithm\n",
    "def findClusters(db, dbscanDataSet):\n",
    "    core_samples_mask = np.zeros_like(db.labels_, dtype=bool) #return an array of zeros with the same shape as labels\n",
    "    core_samples_mask[db.core_sample_indices_] = True #place true where the index leads to a point which is in a cluster\n",
    "    labels = db.labels_\n",
    "    unique_labels = set(labels)\n",
    "    xy = np.array([])\n",
    "    for label in unique_labels:\n",
    "        if label == -1:\n",
    "            continue\n",
    "        class_member_mask = (labels == label) #mask all cluster members\n",
    "        if len(xy) == 0:\n",
    "            xy = dbscanDataSet[class_member_mask & core_samples_mask]\n",
    "        else:    \n",
    "            xy = np.concatenate((xy, dbscanDataSet[class_member_mask & core_samples_mask]),axis=0)\n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tlvStream in tlvData:\n",
    "    tlvStream = np.frombuffer(tlvStream, dtype = 'uint8')\n",
    "    \n",
    "    #tlv header\n",
    "    index = 0\n",
    "    #tlv header parsing\n",
    "    tlvType = tlvStream[index:index+4].view(dtype=np.uint32)\n",
    "    tlvLength = tlvStream[index+4:index+8].view(dtype=np.uint32)\n",
    "    \n",
    "    index += tlvHeaderLengthInBytes\n",
    "    tlvDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "\n",
    "    if tlvType == 6: \n",
    "        numberOfPoints = tlvDataLength/pointLengthInBytes\n",
    "        p = tlvStream[index:index+tlvDataLength[0]].view(np.single)\n",
    "        pointCloud = np.reshape(p,(4, int(numberOfPoints)),order=\"F\")\n",
    "\n",
    "        if not(pointCloud is None):\n",
    "            #constrain point cloud to within the effective sensor range\n",
    "            #range 1 < x < 6\n",
    "            #azimuth -50 deg to 50 deg\n",
    "            #check whether corresponding range and azimuth data are within the constraints\n",
    "\n",
    "            effectivePointCloud = np.array([])\n",
    "            for index in range(0, len(pointCloud[0,:])):\n",
    "                if (pointCloud[0,index] > 1 and pointCloud[0,index] < 6) and (pointCloud[1, index] > -50*np.pi/180 and pointCloud[1, index] < 50*np.pi/180):\n",
    "                    #concatenate columns to the new point cloud\n",
    "                    if len(effectivePointCloud) == 0:\n",
    "                        effectivePointCloud = np.reshape(pointCloud[:, index], (4,1), order=\"F\")\n",
    "                    else:\n",
    "                        point = np.reshape(pointCloud[:, index], (4,1),order=\"F\")\n",
    "                        effectivePointCloud = np.hstack((effectivePointCloud, point))\n",
    "\n",
    "            if len(effectivePointCloud) != 0:\n",
    "                posX = np.multiply(effectivePointCloud[0,:], np.sin(effectivePointCloud[1,:]))\n",
    "                posY = np.multiply(effectivePointCloud[0,:], np.cos(effectivePointCloud[1,:]))\n",
    "                \n",
    "                #create DBSCAN dataset - find a more efficient way to do this\n",
    "                dbscanDataSet = createDBSCANDataset(posX, posY)\n",
    "                        \n",
    "                #run DBSCAN\n",
    "                dbLoose = DBSCAN(eps=0.3,metric='euclidean',min_samples=10).fit(dbscanDataSet) #loose constraints\n",
    "                xy1 = findClusters(dbLoose, dbscanDataSet)\n",
    "                if len(xy1) == 0:\n",
    "                    s1.setData([],[])\n",
    "                else:   \n",
    "                    s1.setData(xy1[:, 0],xy1[:, 1])\n",
    "                QtGui.QApplication.processEvents() \n",
    "                s.setData(posX,posY)\n",
    "                QtGui.QApplication.processEvents() \n",
    "                time.sleep(0.04)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Level DBSCAN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tlvStream in tlvData:\n",
    "    tlvStream = np.frombuffer(tlvStream, dtype = 'uint8')\n",
    "    \n",
    "    #tlv header\n",
    "    index = 0\n",
    "    #tlv header parsing\n",
    "    tlvType = tlvStream[index:index+4].view(dtype=np.uint32)\n",
    "    tlvLength = tlvStream[index+4:index+8].view(dtype=np.uint32)\n",
    "    \n",
    "    index += tlvHeaderLengthInBytes\n",
    "    tlvDataLength = tlvLength - tlvHeaderLengthInBytes\n",
    "\n",
    "    if tlvType == 6: \n",
    "        numberOfPoints = tlvDataLength/pointLengthInBytes\n",
    "        p = tlvStream[index:index+tlvDataLength[0]].view(np.single)\n",
    "        pointCloud = np.reshape(p,(4, int(numberOfPoints)),order=\"F\")\n",
    "\n",
    "        if not(pointCloud is None):\n",
    "            #constrain point cloud to within the effective sensor range\n",
    "            #range 1 < x < 6\n",
    "            #azimuth -50 deg to 50 deg\n",
    "            #check whether corresponding range and azimuth data are within the constraints\n",
    "\n",
    "            effectivePointCloud = np.array([])\n",
    "            for index in range(0, len(pointCloud[0,:])):\n",
    "                if (pointCloud[0,index] > 1 and pointCloud[0,index] < 6) and (pointCloud[1, index] > -50*np.pi/180 and pointCloud[1, index] < 50*np.pi/180):\n",
    "                    #concatenate columns to the new point cloud\n",
    "                    if len(effectivePointCloud) == 0:\n",
    "                        effectivePointCloud = np.reshape(pointCloud[:, index], (4,1), order=\"F\")\n",
    "                    else:\n",
    "                        point = np.reshape(pointCloud[:, index], (4,1),order=\"F\")\n",
    "                        effectivePointCloud = np.hstack((effectivePointCloud, point))\n",
    "\n",
    "            if len(effectivePointCloud) != 0:\n",
    "                posX = np.multiply(effectivePointCloud[0,:], np.sin(effectivePointCloud[1,:]))\n",
    "                posY = np.multiply(effectivePointCloud[0,:], np.cos(effectivePointCloud[1,:]))\n",
    "                \n",
    "                #create DBSCAN dataset - find a more efficient way to do this\n",
    "                dbscanDataSet = createDBSCANDataset(posX, posY)\n",
    "                        \n",
    "                #run DBSCAN\n",
    "                dbLoose = DBSCAN(eps=0.4,metric='euclidean',min_samples=12).fit(dbscanDataSet) #loose constraints\n",
    "                xy1 = findClusters(dbLoose, dbscanDataSet)\n",
    "                dbTight = DBSCAN(eps=0.1,metric='euclidean',min_samples=10).fit(xy1) #loose constraints\n",
    "                xy2 = findClusters(dbTight, xy1)\n",
    "                \n",
    "                s1.setData(xy2[:, 0],xy2[:, 1])\n",
    "                QtGui.QApplication.processEvents() \n",
    "                s.setData(posX,posY)\n",
    "                QtGui.QApplication.processEvents() \n",
    "                time.sleep(0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
